**Проблема:** Unicode символы это числа из таблица кодировки. Но исторически сложилось что числа могут быть записана в разном порядке. 

**Little-endian** означает: младший (наименее значимый) байт хранится по меньшему адресу (сначала в памяти). 

**Big-endian** — наоборот: сначала старший (наиболее значимый) байт.

Поэтому и unicode кодировка может быть и LE и BE

**Причины:** 
В старых архитектурах приходилось много работать с числами разной разрядности. Например одновременно и с 8-ми битными и 16-ти битными. Если записывать их наоборот (сначала младшие разряды потом старшие) то экономится операция сдвига для более длинных чисел по сравнению с короткими. Их можно читать сразу "с конца".  Кроме чтения экономились арифметические операции основанные на сдвигах регистров. 
С тех пор LE это способ по умолчанию при работе с числами процесорах x86, x86-64, ARM в обычном режиме и файловых системах `win*`, `*nix` . 
Но в сетевом оборудовании сложился дефолт BE. Поэтому для сохранения обратной совместимости не меняют дефолты а используют явную конвертацию. 

